html_text()%>%
str_replace_all("[[:punct:]]", " ")}
news_source<-c("scmp","scmp","scmp")
scmp_links<-c("http://www.scmp.com/news/china/diplomacy-defence/article/2131261/china-needs-more-nuclear-warheads-deter-us-threat",
"http://www.scmp.com/news/world/united-states-canada/article/2131164/furious-melania-was-blindsided-report-trumps-payoff",
"http://www.scmp.com/news/world/united-states-canada/article/2131278/donald-trump-review-memo-alleging-intelligence")
text<-list.ungroup(lapply(scmp_links, get_scmp_text))
text
get_scmp_text("http://www.scmp.com/news/world/united-states-canada/article/2131278/donald-trump-review-memo-alleging-intelligence")
get_scmp_text <- function(linkk){
read_html(linkk)%>%
html_nodes("v2-processed")%>%
html_text()%>%
str_replace_all("[[:punct:]]", " ")}
TextPreprocessing(get_scmp_text("http://www.scmp.com/news/world/united-states-canada/article/2131278/donald-trump-review-memo-alleging-intelligence"))
get_scmp_text <- function(linkk){
read_html(linkk)%>%
html_nodes("v2-processed")%>%
html_text()%>%
str_replace_all("[[:punct:]]", " ")}
TextPreprocessing(get_scmp_text("http://www.scmp.com/news/world/united-states-canada/article/2131278/donald-trump-review-memo-alleging-intelligence"))
get_scmp_text("http://www.scmp.com/news/world/united-states-canada/article/2131278/donald-trump-review-memo-alleging-intelligence")
get_scmp_text <- function(linkk){
read_html(linkk)%>%
html_nodes("p.v2-processed")%>%
html_text()%>%
str_replace_all("[[:punct:]]", " ")}
get_scmp_text("http://www.scmp.com/news/world/united-states-canada/article/2131278/donald-trump-review-memo-alleging-intelligence")
get_scmp_text("http://www.scmp.com/news/world/united-states-canada/article/2131278/donald-trump-review-memo-alleging-intelligence")
get_scmp_text <- function(linkk){
read_html(linkk)%>%
html_nodes(xpath = '//*[@id="block-system-main"]/div[1]/div[3]/div/div[1]/div[2]/div[2]/div[1]/div/p[1]')
str_replace_all("[[:punct:]]", " ")}
get_scmp_text("http://www.scmp.com/news/world/united-states-canada/article/2131278/donald-trump-review-memo-alleging-intelligence")
get_scmp_text <- function(linkk){
read_html(linkk)%>%
html_nodes(xpath = '//*[@id="block-system-main"]/div[1]/div[3]/div/div[1]/div[2]/div[2]/div[1]/div/p[1]')%>%
str_replace_all("[[:punct:]]", " ")}
get_scmp_text("http://www.scmp.com/news/world/united-states-canada/article/2131278/donald-trump-review-memo-alleging-intelligence")
get_scmp_text <- function(linkk){
read_html(linkk)%>%
html_nodes(xpath = '//*[@id="block-system-main"]/div[1]/div[3]/div/div[1]/div[2]/div[2]/div[1]/div')%>%
str_replace_all("[[:punct:]]", " ")}
get_scmp_text("http://www.scmp.com/news/world/united-states-canada/article/2131278/donald-trump-review-memo-alleging-intelligence")
get_scmp_text <- function(linkk){
read_html(linkk)%>%
html_nodes(xpath = '//*[@id="block-system-main"]/div[1]/div[3]/div/div[1]/div[2]/div[2]/div[1]/div')%>%
html_text()%>%
str_replace_all("[[:punct:]]", " ")}
get_scmp_text("http://www.scmp.com/news/world/united-states-canada/article/2131278/donald-trump-review-memo-alleging-intelligence")
TextPreprocessing(get_scmp_text("http://www.scmp.com/news/world/united-states-canada/article/2131278/donald-trump-review-memo-alleging-intelligence"))
TextPreprocessing<-function(x){
x = gsub('http\\S+\\s*', '', x) ## Remove URLs
x = gsub('\\b+RT', '', x) ## Remove RT
x = gsub('#\\S+', '', x) ## Remove Hashtags
x = gsub('@\\S+', '', x) ## Remove Mentions
x = gsub('[[:cntrl:]]', '', x) ## Remove Controls and special characters
x = gsub("\\d", '', x) ## Remove Controls and special characters
x = gsub('[[:punct:]]', '', x) ## Remove Punctuations
x = gsub("^[[:space:]]*","",x) ## Remove leading whitespaces
x = gsub("[[:space:]]*$","",x) ## Remove trailing whitespaces
x = gsub('[[:digit:]]+', '', x)
x = tolower(x)
}
get_scmp_text <- function(linkk){
read_html(linkk)%>%
html_nodes(xpath = '//*[@id="block-system-main"]/div[1]/div[3]/div/div[1]/div[2]/div[2]/div[1]/div')%>%
html_text()%>%
str_replace_all("[[:punct:]]", " ")%>%
str_replace_all("[[:punct:]]", " ")}
get_practice_text <- function(linkk){
read_html(linkk)%>%
html_nodes("p")%>%
html_text()%>%
str_replace_all("[[:punct:]]", " ")}
get_practice_text("http://www.scmp.com/news/world/united-states-canada/article/2131278/donald-trump-review-memo-alleging-intelligence")
get_practice_text <- function(linkk){
read_html(linkk)%>%
html_nodes(xpath='//*[@id="block-system-main"]/div[1]/div[3]/div/div[1]/div[2]/div[2]/div[1]/div/p[2]')%>%
html_text()%>%
str_replace_all("[[:punct:]]", " ")}
get_practice_text("http://www.scmp.com/news/world/united-states-canada/article/2131278/donald-trump-review-memo-alleging-intelligence")
get_practice_text <- function(linkk){
read_html(linkk)%>%
html_nodes(xpath='//*[@id="block-system-main"]/div[1]/div[3]/div/div[1]/div[2]/div[2]/div[1]/div')%>%
html_text()%>%
str_replace_all("[[:punct:]]", " ")}
get_practice_text("http://www.scmp.com/news/world/united-states-canada/article/2131278/donald-trump-review-memo-alleging-intelligence")
mean(1,2,3,4,5,6)
k<-(1,2,3,4,5,6)
k<-c(1,2,3,4,5,6)
mean(k)
mean1<-function(x){
sum(x)/length(x)
}
mean1(k)
news_source<-c("CNN","CNN","CNN")
cnn_links<-c("https://www.cnn.com/2018/01/21/entertainment/kristen-bell-2018-sag-awards-host/index.html",
"https://www.cnn.com/2018/01/22/politics/kfile-higbie-book-pulled/index.html",
"https://www.cnn.com/2018/01/23/politics/house-senate-showdown-immigration/index.html")
text<-list.ungroup(lapply(cnn_links, get_cnn_text))
text<-as.character(TextPreprocessing(text))
da<-lapply(cnn_links, get_cnn_date)
date<-list.ungroup(lapply(da,format_cnn_date))
frame1<-data.frame(cnn_links,text,date,news_source)
sentframe<-data.frame(list.rbind(lapply(frame1$text,add_sentiment)))
View(sentframe)
View(frame1)
frame2<-cbind(sentframe,frame1)
View(frame2)
frame2<-cbind(frame1,sentframe)
docs <- Corpus(VectorSource("https://www.cnn.com/2018/01/21/entertainment/kristen-bell-2018-sag-awards-host/index.html"))
docs <- tm_map(docs, removeWords, stopwords("english"))
dtm <- DocumentTermMatrix(docs)
ldaOut <-LDA(dtm,3, method="Gibbs")
ldaOut.terms <- as.data.frame(terms(ldaOut,10))
View(ldaOut.terms)
topicmod("https://www.cnn.com/2018/01/21/entertainment/kristen-bell-2018-sag-awards-host/index.html")
2500000+1700000
(2500000+1700000)/2500000
2500000/(2500000+1700000)
(2500000/(2500000+1700000))-.28
library(rvest)
read_html('https://www.cnn.com/')%>%
html_node(xpath = '//article/div/div/h3/a')%>%
html_text()
read_html('https://www.cnn.com/')%>%
html_node(xpath = '//*[@id="homepage1-zone-1"]/div[2]/div/div[3]/ul/li[6]/article/div/div/h3/a')%>%
html_text()
read_html('https://www.cnn.com/')%>%
html_node('article')%>%
html_text()
read_html('https://www.cnn.com/')%>%
html_node('center')%>%
html_text()
combi_c<-read.csv("C_hhold_train.csv",stringsAsFactors = TRUE, header = TRUE)
setwd("~/MLProjects")
restart()
rs.restartR()
rs.restart.R()
.rs.restartR()
setwd('C:\Users\Willi\OneDrive\Documents\MLProjects')
setwd('Users\Willi\OneDrive\Documents\MLProjects')
setwd('C:/Users/Willi/OneDrive/Documents/MLProjects')
combi_c<-read.csv("C_hhold_train.csv",stringsAsFactors = TRUE, header = TRUE)
combi_c_indiv <- read.csv("C_indiv_train.csv", stringsAsFactors = TRUE, header = TRUE)
combi_c_indiv <- subset( combi_c_indiv, select = -c(iid, poor,country ) )
combi_c_indiv <- combi_c_indiv[!duplicated(combi_c_indiv$id), ]
combi_c <-join(combi_c, combi_c_indiv, by='id', type='inner')
library(caret)
library(tidyverse)
setwd('C:/Users/Willi/OneDrive/Documents/MLProjects')
combi_c<-read.csv("C_hhold_train.csv",stringsAsFactors = TRUE, header = TRUE)
combi_c_indiv <- read.csv("C_indiv_train.csv", stringsAsFactors = TRUE, header = TRUE)
combi_c_indiv <- subset( combi_c_indiv, select = -c(iid, poor,country ) )
combi_c_indiv <- combi_c_indiv[!duplicated(combi_c_indiv$id), ]
combi_c <-join(combi_c, combi_c_indiv, by='id', type='inner')
combi_c<-read.csv("C_hhold_train.csv",stringsAsFactors = TRUE, header = TRUE)
combi_c_indiv <- read.csv("C_indiv_train.csv", stringsAsFactors = TRUE, header = TRUE)
combi_c_indiv <- subset( combi_c_indiv, select = -c(iid, poor,country ) )
combi_c_indiv <- combi_c_indiv[!duplicated(combi_c_indiv$id), ]
combi_c <-dplyr::join(combi_c, combi_c_indiv, by='id', type='inner')
combi_c <-plyr::join(combi_c, combi_c_indiv, by='id', type='inner')
combi_c<-read.csv("C_hhold_train.csv",stringsAsFactors = TRUE, header = TRUE)
combi_c_indiv <- read.csv("C_indiv_train.csv", stringsAsFactors = TRUE, header = TRUE)
combi_c_indiv <- subset( combi_c_indiv, select = -c(iid, poor,country ) )
combi_c_indiv <- combi_c_indiv[!duplicated(combi_c_indiv$id), ]
combi_c <-plyr::join(combi_c, combi_c_indiv, by='id', type='inner')
combi_c$id<-NULL
combi_c1<-(na.omit(combi_c))
poor<-data.frame(combi_c1$poor)
names(poor) <- ("poor")
combi_c1$poor<-NULL
nzv <- nearZeroVar(combi_c1)
combi_c1<-combi_c1[,-nzv]
dim(combi_c1)
combi_c1<-cbind(combi_c1,poor)
levels_detect<-function(x){
if(length(levels(x)) > 34){
return(FALSE)
}else{
return(TRUE)
}
}
excess_levels<-lapply(combi_c1,levels_detect)
name_removec<-names(which(excess_levels==FALSE))
combi_c1<-combi_c1[ , !(names(combi_c1) %in% name_removec)]
length(colnames(combi_c1)
length(colnames(combi_c1))
length(colnames(combi_c1))
length(colnames(combi_c1))-1
length(colnames(combi_c1))-1
control <- rfeControl(functions=rfFuncs, method="cv", number=10)
# run the RFE algorithm
resultsc <- rfe(combi_c1[,1:(length(colnames(combi_c1))-1)], combi_c1[,length(colnames(combi_c1))], rfeControl=control, metric = "Accuracy")
predictors(resultsc)->topvarsc
plot(resultsc, type=c("g", "o"))
combi_c1%>%select(topvarsc,'poor')->combi_c2
preProcValues <- preProcess(combi_c2, method = c("center", "scale"))
dfc <- predict(preProcValues, combi_c2)
dim(dfc)
ggplot(test_set, aes(x = dfc$poor)) +
geom_histogram(binwidth = .05) +
facet_wrap(~obs) +
xlab("Probability of Class #1")
ggplot(dfc, aes(x = poor)) +
geom_histogram(binwidth = .05) +
facet_wrap(~obs) +
xlab("Probability of Class #1")
ggplot(dfc, aes(x = poor)) +
geom_histogram(binwidth = .05)
ggplot(dfc, aes(x = poor)) +
geom_histogram(binwidth = .05) +
stat = "count"
poor<-factor(poor)
poor<-as.factor(poor)
poor<-data.frame(as.factor(combi_c1$poor))
is.factor(combi_c1$poor)
dfc$poor<-as.factor(dfc$poor)
ggplot(dfc, aes(x = poor)) +
geom_histogram(binwidth = .05) +
facet_wrap(~obs) +
xlab("Probability of Poverty")
ggplot(dfc, aes(x = poor)) +
geom_histogram(binwidth = .05) +
xlab("Probability of Poverty")
ggplot(dfc, aes(x = poor)) +
geom_histogram(stat = "identity") +
xlab("Probability of Poverty")
ggplot(dfc, aes(x = poor)) +
geom_bar(stat = "identity") +
xlab("Probability of Poverty")
ggplot(dfc, aes(x = poor)) +
geom_bar(stat = "bin") +
xlab("Probability of Poverty")
ggplot(dfc, aes(x=poor)) +
geom_bar(stat = "bin",width = .05, fill="steelblue") +
theme_minimal()
xlab("Probability of Poverty")
ggplot(dfc, aes(x=poor)) +
geom_bar(stat = "identity",width = .05, fill="steelblue") +
theme_minimal()
xlab("Probability of Poverty")
ggplot(dfc, aes(x=poor,y=count)) +
geom_bar(stat = "identity",width = .05, fill="steelblue") +
theme_minimal()
xlab("Probability of Poverty")
qplot(data=dfc,x=poor,geom = 'hist')
qplot(data=dfc,x=poor,geom = 'bar')
qplot(data=dfc,x=poor,geom = 'bar',fill="steelblue")
qplot(data=dfc,x=poor,geom = 'bar',fill="blue")
qplot(data=dfc,x=poor,geom = 'bar',fill="red")
qplot(data=dfc,x=poor,geom = 'bar')
dfc.xgb <- caret::train(Xtrainc,
Ytrainc, method = "xgbtree",
trControl = trainControl(method = "cv"))
inTrain <- createDataPartition(dfc2$poor, p = .80, list = FALSE)
Xtrainc<-dfc2[inTrain,c(1:4)]
Ytrainc <- dfc2[inTrain,5]
Xtestc <- dfc2[-inTrain,c(1:4)]
Ytestc <- dfc2[-inTrain,5]
dfc.xgb <- caret::train(Xtrainc,
Ytrainc, method = "xgbtree",
trControl = trainControl(method = "cv"))
inTrain <- createDataPartition(dfc2$poor, p = .80, list = FALSE)
inTrain <- createDataPartition(dfc$poor, p = .80, list = FALSE)
Xtrainc<-dfc2[inTrain,c(1:4)]
Ytrainc <- dfc2[inTrain,5]
Xtestc <- dfc2[-inTrain,c(1:4)]
Ytestc <- dfc2[-inTrain,5]
dfc.xgb <- caret::train(Xtrainc,
Ytrainc, method = "xgbtree",
trControl = trainControl(method = "cv"))
dfc$poor<-as.factor(dfc$poor)
inTrain <- createDataPartition(dfc$poor, p = .80, list = FALSE)
Xtrainc<-dfc[inTrain,c(1:4)]
Ytrainc <- dfc[inTrain,5]
Xtestc <- dfc[-inTrain,c(1:4)]
Ytestc <- dfc[-inTrain,5]
dfc.xgb <- caret::train(Xtrainc,
Ytrainc, method = "xgbtree",
trControl = trainControl(method = "cv"))
dfc.xgb <- caret::train(Xtrainc,
Ytrainc, method = "xgbTree",
trControl = trainControl(method = "cv"))
warnings()
dfc.xgb <- caret::train(x=Xtrainc,
y=Ytrainc, method = "xgbTree",
trControl = trainControl(method = "cv"))
warnings()
dfc.xgb <- caret::train(x=xgb.DMatrix(as.matrix(Xtrainc)),
y=Ytrainc, method = "xgbTree",
trControl = trainControl(method = "cv"))
dfc.xgb <- caret::train(x=dummyVars(Xtrainc)),
y=Ytrainc, method = "xgbTree",
trControl = trainControl(method = "cv"))
dfc.xgb <- caret::train(x=dummyVars(Xtrainc),
y=Ytrainc, method = "xgbTree",
trControl = trainControl(method = "cv"))
install.packages("xgboost")
install.packages("xgboost")
library(xgboost)
dfc.xgb <- caret::train(x=xgb.DMatrix(as.matrix((Xtrainc))),
y=Ytrainc, method = "xgbTree",
trControl = trainControl(method = "cv"))
dfc.xgb <- caret::train(x=xgb.DMatrix(as.matrix(Xtrainc)),
y=Ytrainc, method = "xgbTree",
trControl = trainControl(method = "cv"))
trainc=cbind(Xtrainc,Ytrainc)
dfc.xgb <- caret::train(poor~.,data=trainc, method = "xgbTree",
trControl = trainControl(method = "cv"))
dfc.xgb <- caret::train(trainc$poor~.,data=trainc, method = "xgbTree",
trControl = trainControl(method = "cv"))
dfc.xgb <- caret::train(trainc['poor']~.,data=trainc, method = "xgbTree",
trControl = trainControl(method = "cv"))
dim(dfc)
dfc[17]
dfc$poor<-as.factor(dfc$poor)
inTrain <- createDataPartition(dfc$poor, p = .80, list = FALSE)
Xtrainc<-dfc[inTrain,c(1:16)]
Ytrainc <- dfc[inTrain,17]
Xtestc <- dfc[-inTrain,c(1:17)]
Ytestc <- dfc[-inTrain,17]
trainc=cbind(Xtrainc,Ytrainc)
dfc.xgb <- caret::train(trainc['poor']~.,data=trainc, method = "xgbTree",
trControl = trainControl(method = "cv"))
trainc=cbind(Xtrainc,Ytrainc)
View(trainc)
dfc.xgb <- caret::train(trainc['Ytrainc']~.,data=trainc, method = "xgbTree",
trControl = trainControl(method = "cv"))
dfc.xgb <- caret::train(Ytrainc~.,data=trainc, method = "xgbTree",
trControl = trainControl(method = "cv"))
trellis.par.set(caretTheme())
plot(dfc.xgb)
Accuraciesa<- confusionMatrix(Ytestc,
predict(dfc.xgb, newdata=Xtestc))$overall["Accuracy"]
Accuraciesa
ggplot(dfc.xgb)
dfc.xgb <- caret::train(trainc$Ytrainc~.,data=trainc, method = "xgbTree",
trControl = trainControl(method = "cv"))
dfc.xgb <- caret::train(trainc$Ytrainc~.,data=trainc, method = "xgbTree",
trControl = trainControl(method = "cv"),metric="ROC")
dfc.xgb <- caret::train(trainc$Ytrainc~.,data=trainc, method = "xgbTree",
trControl = trainControl(method = "cv"),classProbs=True, metric="ROC")
dfc.xgb <- caret::train(trainc$Ytrainc~.,data=trainc, method = "xgbTree",
trControl = trainControl(method = "cv",classProbs=True), metric="ROC")
dfc.xgb <- caret::train(trainc$Ytrainc~.,data=trainc, method = "xgbTree",
trControl = trainControl(method = "cv",classProbs=TRUE), metric="ROC")
fitControl <-trainControl(method = "cv",
number = 5,
savePredictions = TRUE,
classProbs = TRUE,
summaryFunction = twoClassSummary
dfc.xgb <- caret::train(trainc$Ytrainc~.,data=trainc, method = "xgbTree",
trainControl=fitControl,metric="ROC")
dfc.xgb <- caret::train(trainc$Ytrainc~.,data=trainc, method = "xgbTree",
trControl=fitControl, metric="ROC")
fitControl <-trainControl(method = "cv",
number = 5,
savePredictions = TRUE,
classProbs = TRUE,
summaryFunction = twoClassSummary
)
dfc.xgb <- caret::train(trainc$Ytrainc~.,data=trainc, method = "xgbTree",
trControl=fitControl, metric="ROC")
dfc.xgb <- caret::train(Ytrainc~.,data=trainc, method = "xgbTree",
trControl=fitControl, metric="ROC")
dfc.xgb <- caret::train(trainc['Ytrainc']~.,data=trainc, method = "xgbTree",
trControl=fitControl, metric="ROC")
poor<-NULL
names(trainc)[17]="poor"
fitControl <-trainControl(method = "cv",
number = 5,
savePredictions = TRUE,
classProbs = TRUE,
summaryFunction = twoClassSummary
)
dfc.xgb <- caret::train(poor~.,data=trainc, method = "xgbTree",
trControl=fitControl, metric="ROC")
trellis.par.set(caretTheme())
ggplot(dfc.xgb)
plot(dfc.xgb)
xgb.accuracies<- confusionMatrix(Ytestc,
predict(dfc.xgb, newdata=Xtestc))$overall["Accuracy"]
dfc.plr <- caret::train(poor~.,data=trainc, method = "plr",
trControl=fitControl, metric="ROC")
dfc.plr <- caret::train(poor~.,data=trainc, method = "plr",
metric="ROC")
dfc.plr <- caret::train(poor~.,data=trainc, method = "plr")
dfc.logit <- glm(poor~.,data=trainc, family = "binomial")
dfc.plr <- glm(poor~.,data=trainc, method = "LogitBoost")
dfc.logit <- caret::train(poor~.,data=trainc, method = "LogitBoost")
dfc.gbm <- caret::train(poor~.,data=trainc, method = "gbm",
trControl=fitControl, metric="ROC")
confusionMatrix(Ytestc, predict(dfc.xgb, newdata=Xtestc))
confusionMatrix(Ytestc, predict(dfc.gbm, newdata=Xtestc))
confusionMatrix(Ytestc, predict(dfc.logit, newdata=Xtestc))
qplot(data=dfc,x=poor,geom = 'bar')
lapply(combi_c1,function(x){
if(is.numeric(x)){
boxplot.stats(x)$out<-NA
}
})
outliers<-c()
lapply(combi_c1,function(x){
if(is.numeric(x)){
boxplot.stats(x)$out->outliers
}
})
outliers
boxplot.stats(combi_c1$mmoCpqWS)$out
View(dfc)
boxplot.stats(dfc$DBjxSUvf)$out
length(boxplot.stats(dfc$DBjxSUvf)$out)
outlier <- function(x) {
x[x < quantile(x,0.25) - 1.5 * IQR(x) | x > quantile(x,0.75) + 1.5 * IQR(x)] <- median(x)
x
}
lapply(dfc function(x){
if(is.numeric(x))
outlier(x)
})
outlier <- function(x) {
x[x < quantile(x,0.25) - 1.5 * IQR(x) | x > quantile(x,0.75) + 1.5 * IQR(x)] <- median(x)
x
}
lapply(dfc function(x){
if(is.numeric(x)){
outlier(x)
}
})
outlier <- function(x) {
x[x < quantile(x,0.25) - 1.5 * IQR(x) | x > quantile(x,0.75) + 1.5 * IQR(x)] <- median(x)
x
}
lapply(dfc, function(x){
if(is.numeric(x)){
outlier(x)
}
})
boxplot.stats(dfc$xFKmUXhu)$out
boxplot.stats(dfc$xFKmUXhu)$out<-NA
boxplot.stats(dfc$xFKmUXhu)$out =outliers
boxplot.stats(dfc$xFKmUXhu)$out = outliers
outlier <- function(x) {
x[x < quantile(x,0.25) - 1.5 * IQR(x) | x > quantile(x,0.75) + 1.5 * IQR(x)] <- median(x)
x
}
dfc2<-lapply(dfc, function(x){
if(is.numeric(x)){
outlier(x)
}
})
boxplot.stats(dfc2$xFKmUXhu)$out
dfc$xFKmUXhu==dfc2$xFKmUXhu
inTrain <- createDataPartition(dfc2$poor, p = .80, list = FALSE)
Xtrainc<-dfc2[inTrain,c(1:16)]
Ytrainc <- dfc2[inTrain,17]
Xtestc <- dfc2[-inTrain,c(1:17)]
Ytestc <- dfc2[-inTrain,17]
trainc=cbind(Xtrainc,Ytrainc)
names(trainc)[17]="poor"
fitControl <-trainControl(method = "cv",
number = 5,
savePredictions = TRUE,
classProbs = TRUE,
summaryFunction = twoClassSummary
)
dfc.xgb <- caret::train(poor~.,data=trainc, method = "xgbTree",
trControl=fitControl, metric="ROC")
View(dfc2)
dfc2=as.data.frame(dfc2=!NULL)
dfc2=!NULL
dfc2!=NULL
which(dfc2!=NULL)
outlier <- function(x) {
x[x < quantile(x,0.25) - 1.5 * IQR(x) | x > quantile(x,0.75) + 1.5 * IQR(x)] <- median(x)
x
}
dfc2<-ldply(dfc, function(x){
if(is.numeric(x)){
outlier(x)
}
})
outlier <- function(x) {
x[x < quantile(x,0.25) - 1.5 * IQR(x) | x > quantile(x,0.75) + 1.5 * IQR(x)] <- median(x)
x
}
dfc2<-plyr::ldply(dfc, function(x){
if(is.numeric(x)){
outlier(x)
}
})
View(dfc2)
dfc2=gather(dfc2)
dfc2<-plyr::ldply(dfc, function(x){
if(is.numeric(x)){
outlier(x)
}
})
combi_a<-read.csv("A_hhold_train.csv",stringsAsFactors = TRUE, header = TRUE)
combi_a_indiv <- read.csv("A_indiv_train.csv", stringsAsFactors = TRUE, header = TRUE)
combi_a_indiv <- subset( combi_a_indiv, select = -c(iid, poor,country ) )
combi_a_indiv <- combi_a_indiv[!duplicated(combi_a_indiv$id), ]
combi_a <-join(combi_a, combi_a_indiv, by='id', type='inner')
library(plyr)
combi_a <-join(combi_a, combi_a_indiv, by='id', type='inner')
combi_b<-read.csv("B_hhold_train.csv",stringsAsFactors = TRUE, header = TRUE)
combi_b_indiv <- read.csv("B_indiv_train.csv", stringsAsFactors = TRUE, header = TRUE)
combi_b_indiv <- subset( combi_b_indiv, select = -c(iid, poor,country ) )
combi_b_indiv <- combi_b_indiv[!duplicated(combi_b_indiv$id), ]
combi_b <-join(combi_b, combi_b_indiv, by='id', type='inner')
